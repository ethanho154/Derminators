# Derminosity Application Plan

# Introduction

The Derminosity application will allow doctors to keep track of moles on patients by annotating a body map which will be taken by a full body imaging system. Integration with Firebase will provide secure storage of patient information while offering doctors a reliable method to store and retrieve this information. Integration with the TensorFlow API is another area of interest for this project so that the application can provide its own analysis on skin lesions. The end goal is to have a lightweight application which can be integrated easily with the full body imaging system which will allow doctors to perform skin cancer check-ups faster, more accurately, and at a lower cost than before.

# Overview

This application will be designed to run on an Android platform which currently dominates the global mobile operating system market shares. The entire application will be written in Java and link together different Activities while the actual UI will be designed through XML. The archictectural pattern used will be a presentation, business, and data layer model which is similar to the model-view-controller model. Ideally, the application will be designed so that the front end and back end will be completely separated. A controller would be responsible for moving around data to be displayed on the front end. As of now, the current design (which can be seen in our presentation slides) has our application start in a login screen. Once succesfully logged in, the doctor will be taken to the main menu which acts as the central hub of the application. From here, the doctor is able to use their phone's camera for closer analysis, download images from Firebase and directly analyze them there, or modify settings for the application (which includes settings for both changing analysis as well as quality of life changes). To ensure optimal data transfer within the application as well as efficient memory usage, multiple LruCaches will be used to store information. Some LruCaches will be instantiated as Singletons for data which multiple Activities will use, and exactly how many of these are needed will be to be determined as the needs of the application change over time. The motivation for this was occurred when there was a need for different Activities to access the same picture (ie. one Activity would provide a body map which can be clicked to zoom in on a certain part and taken to an annotation screen). Going forward into the project, while Firebase data transfer has been shown to work for pictures, a data model still needs to be developed for the body map to determine how information about skin lesions detected will be stored. This task will be primarily left for the data layer which will deal more with talking to Firebase and data storage and retrieval. Another issue which will be challenging but not as necessary is about TensorFlow lite integration in the application. Currently, demo applications implementing TensorFlow lite have been tested to familiarize ourself with implementation of the API. Going forward, TFL is something we would like to incorporate into our apps, first for the downloaded images from the database and later to real-time data processing using the phone's camera. This would include training a model for it to recognize malignent skin lesions as well as integrating it into the code.